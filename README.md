
---

# PARSIMONY, ORDER & BALANCE â€” Compression Principles for MoE

> Open-source implementation for compressing Mixture-of-Experts (MoE) models via **low-rank decomposition (D)**, **expert pruning (P)**, and **expert merging (M)**, with support for **sequential combinations** and **contribution-ratio allocation**.

* **Paper:** PARSIMONY, ORDER AND BALANCE: PRINCIPLES FOR COMPRESSING MIXTURE-OF-EXPERTS MODELS
* **Authors:** Shuangyou Feng, Chenyu Xu, Yi Ding, Zhi Liang, Sihai Zhang
* **Code:** [https://github.com/sonder0127/compression-MoE](https://github.com/sonder0127/compression-MoE)

<!-- ===== Figures at the beginning ===== -->
![Figure 1 â€” Overview of compression strategies and sequential compositions](assets/Methodlogy.png)
*Figure 1. Overview of our MoE compression setting and sequential combinations (D/P/M) with contribution allocations.*

![Figure 8 â€” Best strategy by compression level and method mix](assets/Conclusion_heatmap.png)
*Figure 8. Best-performing strategy across compression levels. Balanced contributions tend to win under higher compression.*

## ğŸ” TL;DR

* æˆ‘ä»¬ç³»ç»ŸåŒ–è¯„æµ‹äº† MoE å‹ç¼©çš„å•æ³•ã€ä¸¤ä¸¤ç»„åˆä¸ä¸‰æ³•é¡ºåºç»„åˆï¼Œå¹¶åœ¨ä¸åŒ**å‹ç¼©ç‡**ä¸**æ–¹æ³•è´¡çŒ®åˆ†é…**ä¸‹ç»™å‡ºå¯¹æ¯”ä¸åŸåˆ™ã€‚ç»“è®ºé«˜åº¦æ¦‚æ‹¬ä¸ºï¼š**Parsimonyï¼ˆèŠ‚åˆ¶ï¼‰ã€Orderï¼ˆé¡ºåºï¼‰ã€Balanceï¼ˆå‡è¡¡ï¼‰**ã€‚
* **D ä¸ P**åœ¨ä»»æ„é¡ºåºä¸‹**ååŒ**ï¼›**M ä¸ D**å¯¹**é¡ºåºæ•æ„Ÿ**ï¼Œé€šå¸¸ **Mâ†’D ä¼˜äº Dâ†’M**ï¼›**P ä¸ M**å¤šä¸º**ä¸­æ€§æˆ–æ‹®æŠ—**ï¼Œä¸” **Mâ†’P å¾€å¾€æ›´å·®**ã€‚
* ä½å‹ç¼©ç‡ä¸‹å•æ³•å·²è¶³å¤Ÿï¼›é«˜å‹ç¼©ç‡ä¸‹åˆç†çš„ç»„åˆæ›´æœ‰æ•ˆï¼›**å‡è¡¡çš„è´¡çŒ®åˆ†é…**é€šå¸¸å¸¦æ¥æ›´ä¼˜ç»“æœã€‚
* é€Ÿåº¦ä¸æ˜¾å­˜ï¼šæ›´é«˜å‹ç¼©é™ä½å³°å€¼æ˜¾å­˜ï¼›æé«˜**åˆ†è§£è´¡çŒ®**èƒ½ç¨³å®šæå‡æ¨ç†é€Ÿåº¦ï¼›å½“å‰©ä½™ä¸“å®¶æ•°ä» â‰¥ top-k æ—¶ï¼Œçº¯å‰ªææˆ–åˆå¹¶å¯¹é€Ÿåº¦æå‡æœ‰é™ã€‚

> ä»¥ä¸Šæ‘˜è¦åŸºäºè®ºæ–‡ä¸­çš„æ–¹æ³•ä¸å®éªŒå°ç»“æ•´ç†ï¼ˆè¯¦è§è®ºæ–‡æ­£æ–‡ä¸å›¾ç¤ºï¼‰ã€‚

---

## ğŸ§© Methods

* **Low-rank Decomposition (D)**ï¼šå¯¹ä¸“å®¶æƒé‡è¿›è¡Œ SVD æˆªæ–­å¾—åˆ°ä½ç§©è¿‘ä¼¼ã€‚
* **Expert Pruning (P)**ï¼šæ®å¤šç§ä¸“å®¶é‡è¦æ€§åº¦é‡ï¼ˆæ¿€æ´»é¢‘ç‡ã€è·¯ç”±æƒé‡ç´¯è®¡ã€è¾“å‡º L2 èŒƒæ•°ç­‰ï¼‰å‰ªé™¤ä½è´¡çŒ®ä¸“å®¶ã€‚
* **Expert Merging (M)**ï¼šå…ˆåˆ†ç»„å†èåˆï¼Œæ”¯æŒ**ä¸»å¯¼ä¸“å®¶èšç±»**ä¸**å…¨å±€ç›¸ä¼¼èšç±»**ï¼›å¯¹åº”è·ç¦»åº¦é‡å¯é€‰ **L2 / Cos**ï¼Œèåˆè§„åˆ™ **LERP / SLERP**ã€‚
* **Sequential Compositions**ï¼šå¦‚ `D+P`ã€`M+D`ã€`P+M`ï¼Œä»¥åŠä¸‰æ³•å¦‚ `P+M_L2+D`ã€‚
* **Contribution Allocation**ï¼šåœ¨å›ºå®šæ€»å‹ç¼©ç‡ä¸‹ï¼Œä¸ºå„æ–¹æ³•åˆ†é…å…¶è´¡çŒ®å æ¯”ï¼Œå½¢æˆäºŒç»´/ä¸‰ç»´æœç´¢é¢ã€‚

---

## ğŸ—‚ï¸ Project Structure

```
compression-MoE/
â”œâ”€ component/
â”‚  â”œâ”€ modeling_compressdeepseek.py   # DeepSeek-MoE compression wrappers
â”‚  â”œâ”€ modeling_compressqwen.py       # Qwen-MoE compression wrappers
â”‚  â”œâ”€ modeling_compressolmoe.py      # OLMoE compression wrappers
â”‚  â”œâ”€ modeling_merging.py            # Expert grouping & merging (dominant/global; LERP/SLERP)
â”‚  â”œâ”€ modeling_pruning.py            # Expert pruning utilities (scoring & mask application)
â”‚  â””â”€ modeling_svdmlp.py             # SVD-based factorization for expert MLP weights
â”œâ”€ configs/
â”‚  â”œâ”€ pruning_merging_svd.json       # Hyperparameter presets for pruning/merging/SVD sweeps
â”‚  â””â”€ ...                            # Additional experiment configs
â”œâ”€ method/
â”‚  â”œâ”€ acc_evaluator.py               # Accuracy evaluator for QA benchmarks
â”‚  â”œâ”€ calcute.py                     # Contribution-ratio calculator (allocation utilities)
â”‚  â”œâ”€ compress_method.py             # Compression method registry & orchestration
â”‚  â”œâ”€ expert_pruning.py              # Implementations of expert-pruning strategies/metrics
â”‚  â””â”€ ppl_evaluator.py               # Perplexity evaluator for language-modeling tasks
â”œâ”€ utils/
â”‚  â”œâ”€ data_utils.py                  # Dataset loading
â”‚  â””â”€ model_utils.py                 # Model loading
â”œâ”€ assets/                           # Figures and static assets for README/docs
â”œâ”€ README.md
â””â”€ pruning_merging_svd.py            # Main CLI entry for joint pruning/merging/SVD pipeline


```

---

## ğŸ“¦ Installation

```bash
# 1) Create env
conda create -n moe-compress python=3.10 -y
conda activate moe-compress


# 2) æœ¬ä»“åº“ä½œä¸ºåŒ…
pip install -e .
```

---

## ğŸš€ Quick Start
æ ¹æ®å‹ç¼©éœ€æ±‚ä¿®æ”¹é…ç½®æ–‡ä»¶

`configs/pruning_merging_svd.json`ï¼ˆç¤ºä¾‹ï¼‰ï¼š

```json
{
    "model_name": "OLMoE",
    "model_path": "outfile/OLMoE/model_saved/ASVD_Seed=3.pt",
    "dataset": "wikitext2",
    "seed": 3,
    "DEV": "cpu",
    "step": 0,
    "updating_nsamples": 16,
  
    "eval": {
      "enabled": true,
      "batch_size": 512,
      "nsamples": 500,
      "wiki_batch_size": 16,
      "wiki_nsamples": 0,
      "gen_seq_len": 1024,
      "model_seq_len": 2048
    },
    "svd": {
      "enabled": true,
      "method": "ASVD",
      "mlp_rank": 300,
      "attn_rank": 2048,
      "compress_ratio": 0.1,
      "whitening_nsamples": 32,
      "load_from_file": false,
      "save_model": false
    },
    "pruning": {
      "enabled": true,
      "eval_nsamples": 256,
      "importance_metrics": "activation_frequency",
      "load_from_file": true,
      "strategy": "fixed",
      "compress_ratio": 0.1,
      "pruning_nsamples": 256,
      "save_model": false
    },
    "merging": {
      "enabled": true,
      "eval_nsamples": 32,
      "eval_object": "weight",
      "metrics": "l2",
      "weighting_factor": "activation_frequency",
      "load_from_file": true,
      "save_model": false,
      "num_expert_group": 59,
      "compress_ratio": 0.1
    },
    "other": {
      "build_basenet": false,
      "num_dominate_expert": 8,
      "fine_tune_path": null
    }
  }
```

---

ç„¶årun
```bash
python pruning_merging_svd.py
```

---

## ğŸ“ˆ Reproducing Key Figures

> æŠŠè®ºæ–‡é‡Œå¯¹åº”å›¾ç‰‡å¯¼å‡ºä¸º PNGï¼Œæ”¾åˆ° `assets/` åç”¨ä¸‹æ–¹ Markdown å¼•ç”¨å³å¯ã€‚

* **Pairwise vs. Single**
  ![Pairwise vs Single](assets/fig2_pairwise.png)
  *æ¯åˆ—å±•ç¤ºå½’ä¸€åŒ–çš„ perplexity ä¸ accuracyï¼›é˜´å½±è¡¨ç¤ºè´¡çŒ®åŒºé—´æå€¼ï¼Œè™šçº¿ä¸ºæœ€ä¼˜ç‚¹ã€‚*

* **Best of Single/Pairwise/Triple**
  ![Single vs Pairwise vs Triple](assets/fig3_best_curves.png)

* **Order Sensitivity Heatmaps**
  ![Order Heatmaps](assets/fig4_order_heatmaps.png)

* **Decomposition â†” Pruning äº¤äº’åˆ†æ**
  ![Set Overlap after Decomposition vs Pruning](assets/fig5_overlap.png)

* **Speed & Peak Memory**
  ![Speed & Memory](assets/fig7_speed_memory.png)

* **Best Strategy by Compression Level**
  ![Best strategy grid](assets/fig8_best_grid.png)

---

## ğŸ§ª Datasets & Tasks

* è¯­è¨€å»ºæ¨¡ï¼š**WikiText-2**, **PTB**
* QAï¼š**OpenBookQA**, **ARC-Easy**, **ARC-Challenge**, **MathQA**
* è¯„æµ‹æŒ‡æ ‡ï¼š**Perplexity / Accuracy**ï¼›åŒæ—¶ç»Ÿè®¡**åå tokens/s**ä¸**å³°å€¼æ˜¾å­˜**ã€‚
* ç¯å¢ƒï¼šç¤ºä¾‹åœ¨ **NVIDIA A100** ä¸Šå®Œæˆï¼Œä½ ä¹Ÿå¯ä»¥åœ¨å…¶ä»– GPU ä¸Šå¤ç°ï¼ˆæ‰¹å¤§å°ä¸ç²¾åº¦å¯èƒ½éœ€è°ƒæ•´ï¼‰ã€‚

---

## ğŸ§  Practical Guidelines

* **Parsimony**ï¼šå‹ç¼©ç‡ä½æ—¶ï¼Œå•ä¸€æ–¹æ³•å¸¸è¶³å¤Ÿï¼›å‹ç¼©ç‡å‡é«˜å†è€ƒè™‘ç»„åˆã€‚
* **Order**ï¼š`Mâ†’D` å¾€å¾€ä¼˜äº `Dâ†’M`ï¼›`Dâ†”P` é¡ºåºå½±å“è¾ƒå°ä½†æ¨èå…ˆ D å Pï¼›`Mâ†’P` å¾€å¾€æ›´å·®ã€‚
* **Balance**ï¼šåœ¨å¯å‹ç¼©é¢„ç®—å†…ï¼Œ**å‡è¡¡**çš„ D ä¸ P å¾€å¾€æ›´ä¼˜ï¼›è¿‡åº¦åˆå¹¶ä¼šæŸä¼¤åç»­åˆ†è§£æ•ˆæœï¼›åªåˆå¹¶æˆ–åªå‰ªæåœ¨æ¿€æ´»ä¸“å®¶æ•°ä» â‰¥ top-k æ—¶ï¼Œå¯¹é€Ÿåº¦æå‡æœ‰é™ã€‚

---



## ğŸ“œ Citation

å¦‚æœä½ è§‰å¾—è¿™ä¸ªä»“åº“å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@inproceedings{feng2025parsimony,
  title     = {Parsimony, Order and Balance: Principles for Compressing Mixture-of-Experts Models},
  author    = {Feng, Shuangyou and Xu, Chenyu and Ding, Yi and Liang, Zhi and Zhang, Sihai},
  booktitle = {Proceedings of ICASSP},
  year      = {2026},
  note      = {Code: \url{https://github.com/sonder0127/compression-MoE}}
}
```

## ğŸ™ Acknowledgements

* åŸºåº§ä¸è·¯ç”±è®¾ç½®å‚è€ƒ OLMoEï¼›æ•°æ®ä¸ä»»åŠ¡æ¥è‡ªå…¬å¼€æ•°æ®é›†ã€‚
